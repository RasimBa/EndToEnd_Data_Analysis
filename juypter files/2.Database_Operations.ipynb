{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd322e1f-fca1-4b6f-9ac5-cddc40b65bca",
   "metadata": {},
   "source": [
    "# Database Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538a615-71ca-44f5-a936-eabe3eabd995",
   "metadata": {},
   "source": [
    "### Importing necessary statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10235cf-0c4b-4227-a87b-b10d6ee6b786",
   "metadata": {},
   "source": [
    "##### Install psycopg2-binary\n",
    "\n",
    "* 'psycopg2-binary' helps you avoid the need to compile 'psycopg2' from source.\n",
    "*  Run: `pip install psycopg2-binary` in your terminal/command prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fab6d7-e934-4ac0-9ee4-d440bd3b7c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /opt/anaconda3/lib/python3.11/site-packages (2.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f1118b-a747-48c8-941a-8ea593e3d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This imports the pandas library, a popular tool for data manipulation and analysis in Python.\n",
    "import pandas as pd\n",
    "\n",
    "#Imports the psycopg2 library, which provides the functionality to connect and interact with PostgreSQL databases.\n",
    "import psycopg2 \n",
    "\n",
    "#It helps create dynamic SQL queries in a safe way by avoiding SQL injection, ensuring safer parameterized query execution.\n",
    "from psycopg2 import sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d950a16-14ad-47fc-a1f9-34fa576a4d66",
   "metadata": {},
   "source": [
    "### Input File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1235a3-9559-4617-b327-9bd846729e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_cleaned_data_path = '../Inputs/leads_cleaned_data.xlsx'\n",
    "leads_in_review_data_path = '../Inputs/leads_in_review_data.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b78d3-38a1-402c-8495-a6ed7479dbb0",
   "metadata": {},
   "source": [
    "###  Clean DataFrame column names for SQL compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32b2606c-17a4-405e-976d-905e63c4916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean column names (rename for SQL compatibility)\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.replace(' ', '_')  # Replacing spaces with underscores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa782d45-b8b2-4b9a-95bd-b591349f22aa",
   "metadata": {},
   "source": [
    "<span style = \"color:blue;font-size:14px\" > [Note]There are some columns like 'country code' and 'cleaned phone number' where the function removes the spaces between words to make them compatible with SQL. This ensures that the column names are SQL-friendly by replacing spaces with underscores. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02988803-b4e7-43d1-8edf-db0092af5cde",
   "metadata": {},
   "source": [
    "### Function to load data and insert it into PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea27add-86ad-4885-80a5-9c606541830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data and insert it into PostgreSQL\n",
    "def insert_data(cursor, conn, df, table_name):\n",
    "    # The unique_id column is already present in the DataFrame\n",
    "    columns = df.columns.tolist()  # Get the column names from the DataFrame\n",
    "\n",
    "    # Create SQL insert query dynamically based on the table name and column names\n",
    "    insert_query = sql.SQL('INSERT INTO {} ({}) VALUES ({}) ON CONFLICT (unique_id) DO NOTHING').format(\n",
    "        sql.Identifier(table_name),\n",
    "        sql.SQL(', ').join(map(sql.Identifier, columns)),\n",
    "        sql.SQL(', ').join(sql.Placeholder() * len(columns))\n",
    "    )\n",
    "\n",
    "    # Insert the data from the DataFrame into the table\n",
    "    cursor.executemany(insert_query.as_string(cursor), df.values.tolist())\n",
    "    conn.commit()\n",
    "    print(f\"Data inserted into {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e9b74-bb3c-4b42-b6d2-2e7adae06d41",
   "metadata": {},
   "source": [
    "### Function for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48648b6-bcfa-46b5-82db-269b2be0bc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL. Server version: PostgreSQL 16.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 13.3.1 20240522 (Red Hat 13.3.1-1), 64-bit\n",
      "Successfully connected to bc56a305-2e83-465b-915e-1a243ff67b41\n",
      "Database: bc56a305-2e83-465b-915e-1a243ff67b41\n",
      "User: baghirli_exam\n",
      "Table 'leads_cleaned' created or already exists.\n",
      "Table 'leads_in_review' created or already exists.\n",
      "Data inserted into leads_cleaned\n",
      "Data inserted into leads_in_review\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# Function to test PostgreSQL connection, create tables, and insert data\n",
    "def test_postgresql_connection(host, port, database, user, password):\n",
    "    conn = None\n",
    "    try:\n",
    "        # Establish the connection\n",
    "        conn = psycopg2.connect(\n",
    "            host=host,\n",
    "            port=port,\n",
    "            dbname=database,\n",
    "            user=user,\n",
    "            password=password\n",
    "        )\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute a simple query\n",
    "        cursor.execute(\"SELECT version();\")\n",
    "        version = cursor.fetchone()\n",
    "        print(f\"Connected to PostgreSQL. Server version: {version[0]}\")\n",
    "\n",
    "        # Get additional connection information\n",
    "        cursor.execute(\"SELECT current_database();\")\n",
    "        db_name = cursor.fetchone()\n",
    "        cursor.execute(\"SELECT current_user;\")\n",
    "        user_name = cursor.fetchone()\n",
    "        print(f\"Successfully connected to {db_name[0]}\")\n",
    "        print(f\"Database: {db_name[0]}\")\n",
    "        print(f\"User: {user_name[0]}\")\n",
    "\n",
    "        # Create the 'leads_cleaned' table\n",
    "        create_cleaned_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS leads_cleaned (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            firma VARCHAR(500),  \n",
    "            street VARCHAR(500), \n",
    "            plz VARCHAR(20),     \n",
    "            city VARCHAR(500),   \n",
    "            telefon VARCHAR(100),  \n",
    "            country VARCHAR(50),\n",
    "            country_code VARCHAR(20), \n",
    "            cleaned_phone_number VARCHAR(100),  \n",
    "            flag VARCHAR(50),\n",
    "            salutation VARCHAR(100),\n",
    "            first_name VARCHAR(100),\n",
    "            surname VARCHAR(100),\n",
    "            digit_length DOUBLE PRECISION,   \n",
    "            firma_length DOUBLE PRECISION,\n",
    "            unique_id VARCHAR(100) UNIQUE  -- Add unique_id column with UNIQUE constraint\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_cleaned_table_query)\n",
    "        print(\"Table 'leads_cleaned' created or already exists.\")\n",
    "\n",
    "        # Create the 'leads_in_review' table\n",
    "        create_review_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS leads_in_review (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            firma VARCHAR(500),\n",
    "            street VARCHAR(500),\n",
    "            plz VARCHAR(20),\n",
    "            city VARCHAR(500),\n",
    "            telefon VARCHAR(100),\n",
    "            country VARCHAR(50),\n",
    "            country_code VARCHAR(20),\n",
    "            cleaned_phone_number VARCHAR(100),\n",
    "            flag VARCHAR(50),\n",
    "            salutation VARCHAR(100),\n",
    "            first_name VARCHAR(100),\n",
    "            surname VARCHAR(100),\n",
    "            digit_length DOUBLE PRECISION,   \n",
    "            firma_length DOUBLE PRECISION,\n",
    "            unique_id VARCHAR(100) UNIQUE  -- Add unique_id column with UNIQUE constraint\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_review_table_query)\n",
    "        print(\"Table 'leads_in_review' created or already exists.\")\n",
    "\n",
    "        # Commit the transaction to save changes\n",
    "        conn.commit()\n",
    "\n",
    "        # load the data from and insert it into the tables\n",
    "        # Load and clean data for leads_cleaned\n",
    "        leads_cleaned_data = clean_column_names(pd.read_excel(leads_cleaned_data_path))\n",
    "        leads_in_review_data = clean_column_names(pd.read_excel(leads_in_review_data_path))\n",
    "\n",
    "        # Insert the data into both tables\n",
    "        insert_data(cursor, conn, leads_cleaned_data, 'leads_cleaned')\n",
    "        insert_data(cursor, conn, leads_in_review_data, 'leads_in_review')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while connecting to PostgreSQL: {e}\")\n",
    "\n",
    "    finally:\n",
    "        if conn:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "\n",
    "# Database credentials\n",
    "admin_host = \"data-mgmt-dev-movido-c44b.l.aivencloud.com\"\n",
    "admin_port = 25680\n",
    "admin_database = \"bc56a305-2e83-465b-915e-1a243ff67b41\"\n",
    "target_user = \"baghirli_exam\"\n",
    "target_user_password = \"AVNS_6BV84RAeLbUKqUO7llr\"\n",
    "\n",
    "# Test the connection, create tables, and insert data\n",
    "test_postgresql_connection(admin_host, admin_port, admin_database, target_user, target_user_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a999415-9041-4d47-951b-6498d4b26f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query_with_pandas(host, port, database, user, password, query):\n",
    "    try:\n",
    "        # Connect to PostgreSQL\n",
    "        conn = psycopg2.connect(\n",
    "            host=host,\n",
    "            port=port,\n",
    "            dbname=database,\n",
    "            user=user,\n",
    "            password=password\n",
    "        )\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch all rows\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        # Get column names\n",
    "        colnames = [desc[0] for desc in cursor.description]\n",
    "\n",
    "        # Create a DataFrame to display the results\n",
    "        df = pd.DataFrame(results, columns=colnames)\n",
    "        print(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while running the query: {e}\")\n",
    "\n",
    "    finally:\n",
    "        if conn:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73abf765-0d19-4ebb-bece-a311f25ddc04",
   "metadata": {},
   "source": [
    "### Some Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20fa11bc-5149-4a51-bcfc-6d5f764edf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running queries for leads_cleaned table:\n",
      "\n",
      "   id                                              firma  \\\n",
      "0   1                            Abschleppdienst Arnolds   \n",
      "1   2                                      AAS-Fink GmbH   \n",
      "2   3                          Allfolia Deutschland GmbH   \n",
      "3   4                              Autohaus Schmohl GmbH   \n",
      "4   5           Autohaus Stürmeyer, Inh. Juri Düsterhoft   \n",
      "5   6       Autohaus Thomas Thies, Inhaber: Thomas Thies   \n",
      "6   7                              Autohaus Musberg GmbH   \n",
      "7   8                        Klingler Fahrzeugtechnik AG   \n",
      "8   9  König Wilhelm Autoteile - Einbrodt & Schubert GbR   \n",
      "9  10                             Autoverwertung Kabashi   \n",
      "\n",
      "                  street    plz                     city  \\\n",
      "0  Völlesbruchstrasse 19  52152                Simmerath   \n",
      "1            Morsbach 39  42857                Remscheid   \n",
      "2            Morsbach 39  42857                Remscheid   \n",
      "3     Potsdamer Str. 175  14469                  Potsdam   \n",
      "4         Hauptstraße 19  26897               Esterwegen   \n",
      "5           Hauptstr. 12  24641               Stuvenborn   \n",
      "6            Steinstr. 2  70771  Leinfelden-Echterdingen   \n",
      "7           Galgenried 2   6370                    Stans   \n",
      "8            Dahlweg 122  48153                  Münster   \n",
      "9           Eibseeweg 1A  70378                Stuttgart   \n",
      "\n",
      "                      telefon country country_code cleaned_phone_number  \\\n",
      "0             0049177-8754883      DE           49           1778754883   \n",
      "1                 172.2086056      DE           49           1722086056   \n",
      "2               +491734636476      DE           49           1734636476   \n",
      "3            0049/160466 6050      DE           49           1604666050   \n",
      "4            0049/175116 5373      DE           49           1751165373   \n",
      "5              00491735330785      DE           49           1735330785   \n",
      "6              00491750397296      DE           49           1750397296   \n",
      "7             0049174-8987808      DE           49           1748987808   \n",
      "8              00491600795434      DE           49           1600795434   \n",
      "9  Hotline: 178-0099678 (+49)      DE           49           1780099678   \n",
      "\n",
      "    flag salutation first_name  surname  digit_length  firma_length  \\\n",
      "0  valid    No data    No data  No data          10.0          23.0   \n",
      "1  valid    No data    No data  No data          10.0          13.0   \n",
      "2  valid    No data    No data  No data          10.0          25.0   \n",
      "3  valid    No data    No data  No data          10.0          21.0   \n",
      "4  valid    No data    No data  No data          10.0          40.0   \n",
      "5  valid    No data    No data  No data          10.0          44.0   \n",
      "6  valid    No data    No data  No data          10.0          21.0   \n",
      "7  valid    No data    No data  No data          10.0          27.0   \n",
      "8  valid    No data    No data  No data          10.0          49.0   \n",
      "9  valid    No data    No data  No data          10.0          22.0   \n",
      "\n",
      "    unique_id  \n",
      "0   cleaned_1  \n",
      "1   cleaned_2  \n",
      "2   cleaned_3  \n",
      "3   cleaned_4  \n",
      "4   cleaned_5  \n",
      "5   cleaned_6  \n",
      "6   cleaned_7  \n",
      "7   cleaned_8  \n",
      "8   cleaned_9  \n",
      "9  cleaned_10  \n",
      "PostgreSQL connection is closed\n",
      "   total_rows\n",
      "0        3722\n",
      "PostgreSQL connection is closed\n",
      "\n",
      "Running queries for leads_in_review table:\n",
      "\n",
      "   id                                             firma  \\\n",
      "0   1                           Autohaus Hentschel GmbH   \n",
      "1   2                             Autohaus Siegmar GmbH   \n",
      "2   3                    Autohaus Zückner GmbH & Co. KG   \n",
      "3   4                                       Auto Böhler   \n",
      "4   5               EJP Frank Bach & Katarzyna Bach GbR   \n",
      "5   6  BREMSKERL-REIBBELAGWERKE Emmerling GMBH & CO. KG   \n",
      "6   7                               Werner Bölling GmbH   \n",
      "7   8            ratioparts® Ersatzteile-Vertriebs GmbH   \n",
      "8   9                          Robert Neugebauer & Sohn   \n",
      "9  10                               Autohaus Peene GmbH   \n",
      "\n",
      "                                     street    plz        city  \\\n",
      "0                     Vahrenwalder Str. 141  30165    Hannover   \n",
      "1                    Anton-Erhardt-Straße 5   9117    Chemnitz   \n",
      "2                             Gildestraße 5  91154        Roth   \n",
      "3                              Ottostraße 6  76227   Karlsruhe   \n",
      "4                       Elisabethstrasse 24   2826     Görlitz   \n",
      "5                               Brakenhof 7  31629      Estorf   \n",
      "6                               Klutestr. 3  59063        Hamm   \n",
      "7  IPAS Industriegebiet - Barentsstrasse 17  53881  Euskirchen   \n",
      "8                   Atzendorfer Straße 4a-6  39418    Staßfurt   \n",
      "9                     An den Bäckerwiesen 1  17489  Greifswald   \n",
      "\n",
      "                              telefon country country_code  \\\n",
      "0         +49_x001D_17_x0011_86221169      DE           49   \n",
      "1  +_x001D__x0004_49179_x0008_9703167      DE           49   \n",
      "2                     0049176-9142078      DE           49   \n",
      "3          /179/00182_x000C__x0007_38      DE           49   \n",
      "4          Hotline: 176-0699874 (+49)      DE           49   \n",
      "5     Telefon: 00 457 CALL 8976 / 173      DE           49   \n",
      "6                       +491521029742      DE           49   \n",
      "7          Hotline: 152-2217051 (+49)      DE           49   \n",
      "8                        /152/6516945      DE           49   \n",
      "9                         176.9029428      DE           49   \n",
      "\n",
      "    cleaned_phone_number      flag salutation first_name  surname  \\\n",
      "0        117001186221169  bad data    No data    No data  No data   \n",
      "1  100044917900089703167  bad data    No data    No data  No data   \n",
      "2             1769142078  bad data    No data    No data  No data   \n",
      "3      17900182000000738  bad data    No data    No data  No data   \n",
      "4             1760699874  bad data    No data    No data  No data   \n",
      "5             4578976173  bad data    No data    No data  No data   \n",
      "6             1521029742  bad data    No data    No data  No data   \n",
      "7             1522217051  bad data    No data    No data  No data   \n",
      "8             1526516945  bad data    No data    No data  No data   \n",
      "9             1769029428  bad data    No data    No data  No data   \n",
      "\n",
      "   digit_length  firma_length unique_id  \n",
      "0          15.0          23.0     bad_1  \n",
      "1          21.0          21.0     bad_2  \n",
      "2          10.0          30.0     bad_3  \n",
      "3          17.0          11.0     bad_4  \n",
      "4          10.0          35.0     bad_5  \n",
      "5          10.0          48.0     bad_6  \n",
      "6          10.0          19.0     bad_7  \n",
      "7          10.0          38.0     bad_8  \n",
      "8          10.0          24.0     bad_9  \n",
      "9          10.0          19.0    bad_10  \n",
      "PostgreSQL connection is closed\n",
      "   total_rows\n",
      "0         384\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# Queries for leads_cleaned\n",
    "\n",
    "# Query 1: Select all data from leads_cleaned\n",
    "query_1_cleaned = \"SELECT * FROM leads_cleaned LIMIT 10;\"  # Limiting to 10 for display\n",
    "\n",
    "# Query 2: Count the number of rows in leads_cleaned\n",
    "query_2_cleaned = \"SELECT COUNT(*) AS total_rows FROM leads_cleaned;\"\n",
    "\n",
    " \n",
    "\n",
    "# Queries for leads_in_review\n",
    "\n",
    "# Query 1: Select all data from leads_in_review\n",
    "query_1_review = \"SELECT * FROM leads_in_review LIMIT 10;\"  # Limiting to 10 for display\n",
    "\n",
    "# Query 2: Count the number of rows in leads_in_review\n",
    "query_2_review = \"SELECT COUNT(*) AS total_rows FROM leads_in_review;\"\n",
    "\n",
    "\n",
    "\n",
    "# Run queries for leads_cleaned\n",
    "print(\"Running queries for leads_cleaned table:\\n\")\n",
    "run_query_with_pandas(admin_host, admin_port, admin_database, target_user, target_user_password, query_1_cleaned)\n",
    "run_query_with_pandas(admin_host, admin_port, admin_database, target_user, target_user_password, query_2_cleaned)\n",
    "\n",
    "\n",
    "# Run queries for leads_in_review\n",
    "print(\"\\nRunning queries for leads_in_review table:\\n\")\n",
    "run_query_with_pandas(admin_host, admin_port, admin_database, target_user, target_user_password, query_1_review)\n",
    "run_query_with_pandas(admin_host, admin_port, admin_database, target_user, target_user_password, query_2_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b644948f-4470-48fe-93de-3799db040519",
   "metadata": {},
   "source": [
    "*For the integration of my datasets (cleaned_data and bad_data) into a PostgreSQL database, I followed a structured approach. First, I ensured that both datasets were cleaned and properly structured, then I added a unique_id column to each dataset to uniquely identify each row during the database insertion process, preventing conflicts or duplication.\n",
    "\n",
    "*One of the main challenges I encountered was the issue of data being overwritten every time I ran the insertion code. Initially, using an auto-incrementing id as the primary key did not prevent duplicate rows, as the id was generated for each new row, even if the data was identical. This led to redundant data being inserted into the tables. Additionally, I faced an issue with column value lengths, which resulted in errors, so I increased the VARCHAR length for certain columns (such as firma and street) to accommodate larger values.\n",
    "\n",
    "*To resolve these issues, I dropped the tables and recreated them with an extended VARCHAR length and a unique_id column to uniquely identify rows. I applied a UNIQUE constraint to the unique_id column (this is done in Data Cleaning file) and used the ON CONFLICT clause in my insertion queries, ensuring that rows with the same unique_id would not be inserted multiple times.\n",
    "\n",
    "*Finally, I successfully inserted both datasets (cleaned_data into the leads_cleaned table and bad_data into the leads_in_review table) without any duplication or data conflicts. This approach maintained data integrity and ensured efficient data insertion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
